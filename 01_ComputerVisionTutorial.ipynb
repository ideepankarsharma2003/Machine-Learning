{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_ComputerVisionTutorial.ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1a4jTH6PXn8WDfAUCVdLCduz1_XC4uMyA",
      "authorship_tag": "ABX9TyP07tWzkFH1YlVZWv09fd/E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ideepankarsharma2003/Machine-Learning/blob/main/01_ComputerVisionTutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzbr6aRANfAN"
      },
      "source": [
        "# **Computer Vision**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxzhksAFQE3M"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZlIRvdRNxQV"
      },
      "source": [
        "## Importing Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_ZZbtpbIueu"
      },
      "source": [
        "!pip install -q kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp '/content/drive/MyDrive/Colab Notebooks/kaggle.json' ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "# ! kaggle datasets list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFTjrvvVJEHe"
      },
      "source": [
        "! kaggle datasets download -d ryanholbrook/car-or-truck\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQizZIijJfCk"
      },
      "source": [
        "! unzip car-or-truck.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsEALbQCOjzu"
      },
      "source": [
        "# 02 Convolution And Relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eTUZmQlOqOe"
      },
      "source": [
        "import numpy as np\n",
        "from itertools import product\n",
        "\n",
        "def show_kernel(kernel, label=True, digits=None, text_size=28):\n",
        "    # Format kernel\n",
        "    kernel = np.array(kernel)\n",
        "    if digits is not None:\n",
        "        kernel = kernel.round(digits)\n",
        "\n",
        "    # Plot kernel\n",
        "    cmap = plt.get_cmap('Blues_r')\n",
        "    plt.imshow(kernel, cmap=cmap)\n",
        "    rows, cols = kernel.shape\n",
        "    thresh = (kernel.max()+kernel.min())/2\n",
        "    # Optionally, add value labels\n",
        "    if label:\n",
        "        for i, j in product(range(rows), range(cols)):\n",
        "            val = kernel[i, j]\n",
        "            color = cmap(0) if val > thresh else cmap(255)\n",
        "            plt.text(j, i, val, \n",
        "                     color=color, size=text_size,\n",
        "                     horizontalalignment='center', verticalalignment='center')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBSj79UEPCAm"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    # Convolution Layer\n",
        "    # weights -----> kernels\n",
        "    # activations -----> feature maps\n",
        "    layers.Conv2D(filters=64, kernel_size=3), # activation is None\n",
        "    # More layers follow\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBUdXjuyPnLu"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Conv2D(filters=64, kernel_size=3, activation='relu') # activation is 'Rectified Linear Unit'\n",
        "    # More layers follow\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtCfgAMFP1oW"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('figure', autolayout=True)\n",
        "plt.rc('axes', labelweight='bold', labelsize='large',\n",
        "       titleweight='bold', titlesize=18, titlepad=10)\n",
        "plt.rc('image', cmap='BuPu')\n",
        "\n",
        "image_path = '/content/drive/MyDrive/Colab Notebooks/03-Computer-Vision/hello.jpg'\n",
        "# image_path = 'maxresdefault.jpg'\n",
        "image = tf.io.read_file(image_path)\n",
        "image = tf.io.decode_jpeg(image)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(tf.squeeze(image), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fvj34bDz-qr"
      },
      "source": [
        "image = tf.io.read_file(image_path)\n",
        "image = tf.io.decode_jpeg(image, channels=1)\n",
        "\n",
        "img = tf.squeeze(image).numpy()\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me820mgMQwh2"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# kernel = tf.constant([\n",
        "#     [1, 0, -1],\n",
        "#     [1, 0, -1],\n",
        "#     [1, 0, -1],\n",
        "# ])\n",
        "\n",
        "# plt.figure(figsize=(3, 3))\n",
        "# show_kernel(kernel)\n",
        "\n",
        "kernel = tf.constant([\n",
        "    [1, 1, 1],\n",
        "    [0, 0, 0],\n",
        "    [-1, -1, -1],\n",
        "])\n",
        "\n",
        "plt.figure(figsize=(3, 3))\n",
        "show_kernel(kernel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reGN0SvHQ2DV"
      },
      "source": [
        "# Reformat for batch compatibility.\n",
        "image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "image = tf.expand_dims(image, axis=0)\n",
        "kernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\n",
        "kernel = tf.cast(kernel, dtype=tf.float32)\n",
        "# kernel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohTQ8nJruWqX"
      },
      "source": [
        "conv_fn = tf.nn.conv2d\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78B72v0euVU_"
      },
      "source": [
        "image_filter = conv_fn(\n",
        "    input=image,\n",
        "    filters=kernel,\n",
        "    strides=1,  # or (1, 1)\n",
        "    padding='SAME',\n",
        ")\n",
        "\n",
        "plt.imshow(\n",
        "    # Reformat for plotting\n",
        "    tf.squeeze(image_filter)\n",
        ")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdDzFnOmtPzK"
      },
      "source": [
        "image_filter = tf.nn.conv2d(\n",
        "    input=image,\n",
        "    filters=kernel,\n",
        "    # we'll talk about these two in lesson 4!\n",
        "    strides=1,\n",
        "    padding='SAME',\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(tf.squeeze(image_filter))\n",
        "plt.axis('off')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm9vJKlpN7a9"
      },
      "source": [
        "# 03 Maximum Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21hSnJ_rJrM0"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(filters=64, kernel_size=3), # activation is None\n",
        "    layers.MaxPool2D(pool_size=2),\n",
        "    # More layers follow\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21Mbh7cnRUNw"
      },
      "source": [
        "### Apply Maximum Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLaUGfPlRTmu"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "plt.rc('figure', autolayout=True)\n",
        "plt.rc('axes', labelweight='bold', labelsize='large',\n",
        "       titleweight='bold', titlesize=18, titlepad=10)\n",
        "plt.rc('image', cmap='inferno')\n",
        "warnings.filterwarnings(\"ignore\") # to clean up output cells\n",
        "\n",
        "# Read image\n",
        "image_path = '/content/drive/MyDrive/Colab Notebooks/03-Computer-Vision/hello.jpg'\n",
        "image = tf.io.read_file(image_path)\n",
        "image = tf.io.decode_jpeg(image)\n",
        "\n",
        "image = tf.io.read_file(image_path)\n",
        "image = tf.io.decode_jpeg(image, channels=1)\n",
        "\n",
        "img = tf.squeeze(image).numpy()\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('Original')\n",
        "plt.show()\n",
        "\n",
        "# Define kernel\n",
        "kernel = tf.constant([\n",
        "    [-1, -1, -1],\n",
        "    [-1,  8, -1],\n",
        "    [-1, -1, -1],\n",
        "], dtype=tf.float32)\n",
        "\n",
        "# Reformat for batch compatibility.\n",
        "image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "image = tf.expand_dims(image, axis=0)\n",
        "kernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\n",
        "\n",
        "# Filter step\n",
        "image_filter = tf.nn.conv2d(\n",
        "    input=image,\n",
        "    filters=kernel,\n",
        "    # we'll talk about these two in the next lesson!\n",
        "    strides=1,\n",
        "    padding='SAME'\n",
        ")\n",
        "\n",
        "# Detect step\n",
        "image_detect = tf.nn.relu(image_filter)\n",
        "\n",
        "# Show what we have so far\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(131)\n",
        "plt.imshow(tf.squeeze(image), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('Input')\n",
        "plt.subplot(132)\n",
        "plt.imshow(tf.squeeze(image_filter))\n",
        "plt.axis('off')\n",
        "plt.title('Filter-->Conv')\n",
        "plt.subplot(133)\n",
        "plt.imshow(tf.squeeze(image_detect))\n",
        "plt.axis('off')\n",
        "plt.title('Detect--->ReLU')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF6pTcOCST-Q"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "image_condense = tf.nn.pool(\n",
        "    input=image_detect, # image in the Detect step above\n",
        "    window_shape=(2, 2),\n",
        "    pooling_type='MAX',\n",
        "    # we'll see what these do in the next lesson!\n",
        "    strides=(2, 2),\n",
        "    padding='SAME',\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(tf.squeeze(image_condense))\n",
        "plt.title('MAX-POOLING')\n",
        "plt.axis('off')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YVS1QVNFHiM"
      },
      "source": [
        "### Apply Average Pooling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xTla09NDurD"
      },
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# image_condense = tf.nn.pool(\n",
        "#     input=image_detect, # image in the Detect step above\n",
        "#     window_shape=(8, 8),\n",
        "#     pooling_type='AVG',\n",
        "#     # we'll see what these do in the next lesson!\n",
        "#     strides=(1, 1),\n",
        "#     padding='SAME',\n",
        "# )\n",
        "\n",
        "# plt.figure(figsize=(6, 6))\n",
        "# plt.imshow(tf.squeeze(image_condense))\n",
        "# plt.title('AVERAGE-POOLING')\n",
        "# plt.axis('off')\n",
        "# plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQJ1iOPHSfwY"
      },
      "source": [
        "# print(image_condense)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RirRLYh1FLDC"
      },
      "source": [
        "# **04 The Sliding Window**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXDAc2Q0M6CM"
      },
      "source": [
        "import numpy as np\n",
        "from itertools import product\n",
        "from skimage import draw, transform\n",
        "\n",
        "def circle(size, val=None, r_shrink=0):\n",
        "    circle = np.zeros([size[0]+1, size[1]+1])\n",
        "    rr, cc = draw.circle_perimeter(\n",
        "        size[0]//2, size[1]//2,\n",
        "        radius=size[0]//2 - r_shrink,\n",
        "        shape=[size[0]+1, size[1]+1],\n",
        "    )\n",
        "    if val is None:\n",
        "        circle[rr, cc] = np.random.uniform(size=circle.shape)[rr, cc]\n",
        "    else:\n",
        "        circle[rr, cc] = val\n",
        "    circle = transform.resize(circle, size, order=0)\n",
        "    return circle\n",
        "\n",
        "def show_kernel(kernel, label=True, digits=None, text_size=28):\n",
        "    # Format kernel\n",
        "    kernel = np.array(kernel)\n",
        "    if digits is not None:\n",
        "        kernel = kernel.round(digits)\n",
        "\n",
        "    # Plot kernel\n",
        "    cmap = plt.get_cmap('Blues_r')\n",
        "    plt.imshow(kernel, cmap=cmap)\n",
        "    rows, cols = kernel.shape\n",
        "    thresh = (kernel.max()+kernel.min())/2\n",
        "    # Optionally, add value labels\n",
        "    if label:\n",
        "        for i, j in product(range(rows), range(cols)):\n",
        "            val = kernel[i, j]\n",
        "            color = cmap(0) if val > thresh else cmap(255)\n",
        "            plt.text(j, i, val, \n",
        "                     color=color, size=text_size,\n",
        "                     horizontalalignment='center', verticalalignment='center')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "\n",
        "def show_extraction(image,\n",
        "                    kernel,\n",
        "                    conv_stride=1,\n",
        "                    conv_padding='valid',\n",
        "                    activation='relu',\n",
        "                    pool_size=2,\n",
        "                    pool_stride=2,\n",
        "                    pool_padding='same',\n",
        "                    figsize=(10, 10),\n",
        "                    subplot_shape=(2, 2),\n",
        "                    ops=['Input', 'Filter', 'Detect', 'Condense'],\n",
        "                    gamma=1.0):\n",
        "    # Create Layers\n",
        "    model = tf.keras.Sequential([\n",
        "                    tf.keras.layers.Conv2D(\n",
        "                        filters=1,\n",
        "                        kernel_size=kernel.shape,\n",
        "                        strides=conv_stride,\n",
        "                        padding=conv_padding,\n",
        "                        use_bias=False,\n",
        "                        input_shape=image.shape,\n",
        "                    ),\n",
        "                    tf.keras.layers.Activation(activation),\n",
        "                    tf.keras.layers.MaxPool2D(\n",
        "                        pool_size=pool_size,\n",
        "                        strides=pool_stride,\n",
        "                        padding=pool_padding,\n",
        "                    ),\n",
        "                   ])\n",
        "\n",
        "    layer_filter, layer_detect, layer_condense = model.layers\n",
        "    kernel = tf.reshape(kernel, [*kernel.shape, 1, 1])\n",
        "    layer_filter.set_weights([kernel])\n",
        "\n",
        "    # Format for TF\n",
        "    image = tf.expand_dims(image, axis=0)\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32) \n",
        "    \n",
        "    # Extract Feature\n",
        "    image_filter = layer_filter(image)\n",
        "    image_detect = layer_detect(image_filter)\n",
        "    image_condense = layer_condense(image_detect)\n",
        "    \n",
        "    images = {}\n",
        "    if 'Input' in ops:\n",
        "        images.update({'Input': (image, 1.0)})\n",
        "    if 'Filter' in ops:\n",
        "        images.update({'Filter': (image_filter, 1.0)})\n",
        "    if 'Detect' in ops:\n",
        "        images.update({'Detect': (image_detect, gamma)})\n",
        "    if 'Condense' in ops:\n",
        "        images.update({'Condense': (image_condense, gamma)})\n",
        "    \n",
        "    # Plot\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i, title in enumerate(ops):\n",
        "        image, gamma = images[title]\n",
        "        plt.subplot(*subplot_shape, i+1)\n",
        "        plt.imshow(tf.image.adjust_gamma(tf.squeeze(image), gamma))\n",
        "        plt.axis('off')\n",
        "        plt.title(title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqCKbD1wFrH7"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Conv2D(filters=64,\n",
        "                  kernel_size=3,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  activation='relu'),\n",
        "    layers.MaxPool2D(pool_size=2,\n",
        "                     strides=1,\n",
        "                     padding='same')\n",
        "    # More layers follow\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNlqLR1NFy8c"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('figure', autolayout=True)\n",
        "plt.rc('axes', labelweight='bold', labelsize='large',\n",
        "       titleweight='bold', titlesize=18, titlepad=10)\n",
        "plt.rc('image', cmap='magma')\n",
        "\n",
        "image = circle([64, 64], val=1.0, r_shrink=3)\n",
        "image = tf.reshape(image, [*image.shape, 1])\n",
        "# Bottom sobel\n",
        "kernel = tf.constant(\n",
        "    [[-1, -2, -1],\n",
        "     [0, 0, 0],\n",
        "     [1, 2, 1]],\n",
        ")\n",
        "\n",
        "show_kernel(kernel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yECPDi-LF4qt"
      },
      "source": [
        "show_extraction(\n",
        "    image, kernel,\n",
        "\n",
        "    # Window parameters\n",
        "    conv_stride=1,\n",
        "    pool_size=2,\n",
        "    pool_stride=2,\n",
        "\n",
        "    subplot_shape=(1, 4),\n",
        "    figsize=(14, 6),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW1-WhaBF-TU"
      },
      "source": [
        "show_extraction(\n",
        "    image, kernel,\n",
        "\n",
        "    # Window parameters\n",
        "    # changed the convolution stride to 3\n",
        "    conv_stride=3,\n",
        "    pool_size=2,\n",
        "    pool_stride=2,\n",
        "\n",
        "    subplot_shape=(1, 4),\n",
        "    figsize=(14, 6),    \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qhKbDVrGdJI"
      },
      "source": [
        "# **05 Custom Convnets**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktPHctQzGqXO"
      },
      "source": [
        "### Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbLWt-ppGMoJ"
      },
      "source": [
        "# Imports\n",
        "import os, warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "# Reproducability\n",
        "def set_seed(seed=31415):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "set_seed()\n",
        "\n",
        "# Set Matplotlib defaults\n",
        "plt.rc('figure', autolayout=True)\n",
        "plt.rc('axes', labelweight='bold', labelsize='large',\n",
        "       titleweight='bold', titlesize=18, titlepad=10)\n",
        "plt.rc('image', cmap='magma')\n",
        "warnings.filterwarnings(\"ignore\") # to clean up output cells\n",
        "\n",
        "\n",
        "# Load training and validation sets\n",
        "ds_train_ = image_dataset_from_directory(\n",
        "    '/content/train',\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    image_size=[128, 128],\n",
        "    interpolation='nearest',\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        ")\n",
        "ds_valid_ = image_dataset_from_directory(\n",
        "    '/content/valid',\n",
        "    labels='inferred',\n",
        "    label_mode='binary',\n",
        "    image_size=[128, 128],\n",
        "    interpolation='nearest',\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "# Data Pipeline\n",
        "def convert_to_float(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    return image, label\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "ds_train = (\n",
        "    ds_train_\n",
        "    .map(convert_to_float)\n",
        "    .cache()\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")\n",
        "ds_valid = (\n",
        "    ds_valid_\n",
        "    .map(convert_to_float)\n",
        "    .cache()\n",
        "    .prefetch(buffer_size=AUTOTUNE)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCxvfcu5Hhk0"
      },
      "source": [
        "### Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfxfxODaHXnv"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "\n",
        "    # First Convolutional Block\n",
        "    layers.Conv2D(filters=32, kernel_size=5, activation=\"relu\", padding='same',\n",
        "                  # give the input dimensions in the first layer\n",
        "                  # [height, width, color channels(RGB)]\n",
        "                  input_shape=[128, 128, 3]),\n",
        "    layers.MaxPool2D(),\n",
        "\n",
        "    # Second Convolutional Block\n",
        "    layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n",
        "    layers.MaxPool2D(),\n",
        "\n",
        "    # Third Convolutional Block\n",
        "    layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n",
        "    layers.MaxPool2D(),\n",
        "\n",
        "    # Classifier Head\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(units=6, activation=\"relu\"),\n",
        "    layers.Dense(units=1, activation=\"sigmoid\"),\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Zv6quyWHtPK"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUElbFQIHn-X"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['binary_accuracy']\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    ds_train,\n",
        "    validation_data=ds_valid,\n",
        "    epochs=40,\n",
        "    # epochs=1,\n",
        "    verbose=0,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmK27krHHwJj"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "history_frame = pd.DataFrame(history.history)\n",
        "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
        "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWhQplgBIUVU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}